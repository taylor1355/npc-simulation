[[Useful Papers#Generative Agents]]
## Generative Agents: Interactive Simulacra of Human Behavior
General Notes
- Reading about all of the complex interlinked systems, I'm convinced that the most important way to create a better system is to start very simple and make sure additional functionality is modular. The modularity is very important so that more complexity can be added in a scalable way and the performance of each system can be optimized independently 
- I like how their memory system is influenced by cognitive science. Memories are tagged with creation and last accessed timestamps, which is used to influence the likelihood of recall. Specifically, the retrieval score is proportional to the sum of recency, importance, and relevance
- One form of semantic memory that would be nice to have would be opinions about different people / concepts. The impreciseness of semantic dense vector retrieval is actually beneficial here, since people's opinion about something can be influenced by their opinion on related things.
- I like the idea of visualizing the current action of NPCs using emojis
- Reflections seem pretty crucial to making the memory stream idea work. It would be interesting to represent the reflection tree as a knowledge graph and use knowledge graph specific techniques to manipulate and access it
- Agents should have structured memory in addition to unstructured memory that they access through the memory stream. For example they should have access to a calendar and be able to freely modify the day's working memory scratchpad. Agents can also record the last state they remember of particular items in the world (if the state in question is sufficiently relevant to them)

Paper Summary
- Agent architecture
	- Memory: There is a single memory stream. Each entry consists of a created timestamp, natural language description, and last retrieved timestamp. Retrieval score is based on the sum of recency, importance (LLM prompted to give a 1-10 score upon encoding), and relevance (semantic similarity to query memory given a vector index on the natural language descriptions). Upon retrieving a set of memories (given a query memory, not sure yet how they get that), they are just placed into the LLM's context window. Surely something better involving working memory and selective attention can be done
		- Recency is implemented as an exponential decay
		- Each subscore is normalized to range $[0,1]$
	- 